clc
clear
close all
% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created 10-Mar-2021 12:30:18
%
% This script assumes these variables are defined:
%
%   cancerInputs - input data.
%   cancerTargets - target data.
load cancer_dataset

[x,t] = cancer_dataset;

epoch = [1 2 4 8 16 32 64];
node = [2 8 32];

node_epoch_combo = zeros(3,11);

for s = 4:7

epoch_node_iteration_test_error = zeros(7,3,30);
epoch_node_iteration_train_error = zeros(7,3,30);

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainscg';  % Scaled conjugate gradient backpropagation.

count = 0;

for e_i = 1:7
for n_i = 1:3
for i_i = 1:30
    
% Create a Pattern Recognition Network
hiddenLayerSize = epoch(e_i);
net = patternnet(hiddenLayerSize, trainFcn);
net.trainParam.epochs = node(n_i);
net.trainParam.min_grad = 10e-12;
% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivision
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 50/100;
net.divideParam.valRatio = 0/100;
net.divideParam.testRatio = 50/100;

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'crossentropy';  % Cross-Entropy
%net.performFcn = 'classiferror';  % Classification-error

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotconfusion', 'plotroc'};

% Train the Network
[net,tr] = train(net,x,t);

% Test the Network
y = net(x);
% e = gsubtract(t,y);
% performance = perform(net,t,y)
tind = vec2ind(t);
yind = vec2ind(y);
percentErrors = sum(tind ~= yind)/numel(tind);

tr_testInd = tr.testInd;
tr_trainInd = tr.trainInd;

epoch_node_iteration_test_error(e_i,n_i,i_i) = sum(tind(tr_testInd) ~= yind(tr_testInd))/numel(tind(tr_testInd));
epoch_node_iteration_train_error(e_i,n_i,i_i) = sum(tind(tr_trainInd) ~= yind(tr_trainInd))/numel(tind(tr_trainInd));

count = count + 1;

disp([num2str(round(count*100/630,2)) '%'])

end
end
end


epoch_node_test_error = mean(epoch_node_iteration_test_error,3);
epoch_node_train_error = mean(epoch_node_iteration_test_error,3);

[test_error] = min(epoch_node_test_error(:));
[e_i,n_i] = find(epoch_node_test_error == test_error,1);

node_epoch_combo(1,s) = node(n_i);
node_epoch_combo(2,s) = epoch(e_i);
node_epoch_combo(3,s) = test_error;


disp('best individual classifier uses')
disp(['node: ' num2str(node(n_i))])
disp(['epoch: ' num2str(epoch(e_i))])
disp(['give test error: ' num2str(test_error)])

clear net

end

